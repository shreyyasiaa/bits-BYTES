{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow numpy nltk pillow","metadata":{"execution":{"iopub.status.busy":"2024-05-28T11:20:45.692252Z","iopub.execute_input":"2024-05-28T11:20:45.692926Z","iopub.status.idle":"2024-05-28T11:21:39.002553Z","shell.execute_reply.started":"2024-05-28T11:20:45.692892Z","shell.execute_reply":"2024-05-28T11:21:39.001599Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (9.5.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f571f890c70>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/keras/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f571f892b60>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/keras/\u001b[0m\u001b[33m\n\u001b[0m^C\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport string\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, Add\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom nltk.translate.bleu_score import corpus_bleu\nimport nltk\n\nnltk.download('punkt')\n\n# Define paths\ndataset_dir = '/path/to/Flickr8k'  # Change this to the path where the dataset is located\nimages_dir = os.path.join(dataset_dir, 'Flicker8k_Dataset')\ncaptions_file = os.path.join(dataset_dir, 'Flickr8k.token.txt')\n\n# Load the captions into a dictionary\ndef load_captions(file):\n    captions = {}\n    with open(file, 'r') as f:\n        for line in f:\n            tokens = line.strip().split()\n            image_id, image_caption = tokens[0], tokens[1:]\n            image_id = image_id.split('.')[0]\n            image_caption = ' '.join(image_caption)\n            if image_id not in captions:\n                captions[image_id] = []\n            captions[image_id].append(image_caption)\n    return captions\n\ncaptions = load_captions(captions_file)\n\n# Clean the captions\ndef clean_captions(captions):\n    table = str.maketrans('', '', string.punctuation)\n    for key, desc_list in captions.items():\n        for i in range(len(desc_list)):\n            desc = desc_list[i]\n            desc = desc.split()\n            desc = [word.lower() for word in desc]\n            desc = [w.translate(table) for w in desc]\n            desc = [word for word in desc if len(word) > 1]\n            desc = [word for word in desc if word.isalpha()]\n            desc_list[i] = ' '.join(desc)\n\nclean_captions(captions)\n\n# Convert the captions to a vocabulary\ndef to_vocabulary(captions):\n    all_captions = set()\n    for key in captions.keys():\n        [all_captions.update(d.split()) for d in captions[key]]\n    return all_captions\n\nvocabulary = to_vocabulary(captions)\n\n# Save the captions to a file\ndef save_captions(captions, filename):\n    lines = []\n    for key, desc_list in captions.items():\n        for desc in desc_list:\n            lines.append(key + '\\t' + desc)\n    data = '\\n'.join(lines)\n    with open(filename, 'w') as f:\n        f.write(data)\n\nsave_captions(captions, 'captions.txt')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-28T11:22:13.536707Z","iopub.status.idle":"2024-05-28T11:22:13.537008Z","shell.execute_reply.started":"2024-05-28T11:22:13.536858Z","shell.execute_reply":"2024-05-28T11:22:13.536870Z"},"trusted":true},"execution_count":null,"outputs":[]}]}